\chapter{Continuous State Space Models with Discrete Observations}
\label{chap:eight}

We show how the \polyagamma augmentation strategy can be leveraged 
to render the observations conjugate with linear Gaussian latent structure. 
This allows us to use off-the-shelf inference tools for Gaussian LDS 
models. It also allows us to extend to switching variants of the LDS 
by including another layer of discrete, Markovian states. 
While these models apply directly to Bernoulli and negative-binomial 
observations, we can approximate Poisson observations as a limit of the 
negative binomial. Alternatively, we can use a Poisson thinning model with 
multinomial conditionals to exactly simulate the Poisson model. If time 
and space allow, we will introduce this novel approach in this chapter.
Finally, I will compare these models on the basis of their ability to generalize to 
held out spike counts. Since this is the final chapter, we will also 
provide a comparison against the models introduced in preceding chapters.

\section*{Abstract}
Latent state space models such as linear dynamical systems and hidden Markov models 
are extraordinarily powerful tools for gaining insight into the latent 
structure underlying neural activity. By beginning with simple hypotheses about 
the latent states of neural populations and incorporating additional 
beliefs about the nature of this state and its dynamics, we can compose a
sequence of increasingly sophisticated models and evaluate them in a
statistically rigorous manner.
However, inferring the latent states and parameters of these models is
particularly challenging when presented with discrete spike counts, since the
observation likelihoods are not conjugate with the latent Gaussian structure. 
Thus, we often resort to model-specific approximate inference algorithms which preclude 
rapid model iteration and typically provide only point estimates of the model parameters. 
As a result, it is difficult compare models in a way that is robust to the 
approximation and the particular estimates of the model parameters. 
Here, we develop a unified framework for composing latent state space models and 
performing efficient Bayesian inference by leveraging a data augmentation 
strategy to handle the discrete spike count observations. This framework is
easily extensible, as we demonstrate by constructing an array of latent state space models
with a variety of discrete spike count distributions and fitting them to a
simultaneously recorded population of hippocampal place cells.  
Our Bayesian approach yields a posterior distribution over latent states and
parameters, which enables robust prediction and principled model comparison.
Moreover, we show that our method is very efficient, performing faster than
alternative point-estimation approaches in our experiments.
 
% Latent state space models provide a flexible means 
% of encoding our intuitions and hypotheses about the structure of neural activity 
% in a generative, probabilistic framework, and then testing 
% these hypotheses with statistically rigorous benchmarks. 
% We begin with the simple hypothesis that neural population activity reflects 
% a low dimensional latent state, and by including additional 
% structure we encode our beliefs about the nature of this state and 
% how it evolves over time we compose a nested sequence of 
% increasingly sophisticated hypotheses. These hypotheses 
% correspond to probabilistic models  
 

% We develop a computational and statistical framework modeling neural
% population activity by composing hypotheses about the nature and
% dynamics of the latent population ``state.'' When the data are
% continuous and well modeled by a Gaussian distribution, we can
% leverage a host of well-studied inference algorithms that leverage the
% compositional structure of the model.  However, these methods are not
% applicable to discrete observations like neural spike counts, and
% either general purpose methods or model-specific approximations must
% be used instead.  We develop an alternative approach that leverages a simple
% data augmentation strategy to render these discrete observations
% conjugate with the latent state space model, and thereby enable
% efficient Bayesian inference. With this framework, we can postulate an
% array of models that capture increasingly sophisticated latent
% structure underlying neural activity, efficiently fit the models to
% neural recordings, and compare them on the basis of their ability to
% explain held-out data by integrating over the posterior distribution
% of model parameters. We demonstrate the efficacy of this framework for 
% comparing spiking models of hippocampus and motor cortex. 

% With a sophisticated arsenal of optical and electrophysiological tools, 
% we can now record neural activity at 
% unprecedented scales.  In order to make sense of these massive datasets,
% we need statistical tools to extract latent structure 
% and provide insight into the computational processes that give rise to our data.
% Latent state space models provide a compositional framework for expressing 
% a spectrum of hypotheses about these underlying   
% generative processes.
% All models in this framework share the notion of a latent state, be it continuous, discrete, or mixed,
% and a specification of how that latent state evolves over time. 
% Principal components analysis (PCA), hidden Markov models (HMMs),
% linear dynamical systems (LDSs), and switching linear dynamical systems (SLDSs), 
% are special cases of this framework corresponding to varying hypotheses about 
% the nature of the latent state 

% Neuroscientists probe the computational processes of the brain with an
% arsenal of tools ranging from single cell recordings to whole brain
% calcium fluorescence traces and even behavioral observations. Across
% all domains, recordings exhibit highly structured patterns reflecting
% the dynamic underlying computational processes of interest. These processes can
% often be characterized by the evolution of a latent ``state'' that
% gives rise, via a noisy observation model, to the signals we actually
% measure.  We develop a Bayesian framework for uncovering this latent
% state and learning its dynamics.  This framework consists of a library
% of interpretable building blocks that are composed into structured
% latent state space models; a family of link functions that connect
% the latent state to the observed activity; a scalable Bayesian
% inference algorithm that leverages an auxiliary variable formulation
% for efficient state estimation; and an algorithm for comparing
% alternative models on the basis of their marginal likelihood. We
% demonstrate our framework on a variety of real-world datasets.

\section{Latent State Space Models}
Neural recordings often take the form of a matrix of observed
spike counts,~$\bS$, whose entries,~$s_{n,t}$, denote the number of spikes 
emitted by  neuron~$n$ at time~$t$. Depending on the recording, ``neurons''
may be replaced by voxels or features, and ``spikes'' may be replaced by fluorescence or 
another measurable signal. Latent state space models begin with the assumption 
that these observations are a noisy function of some unobserved instantaneous 
``activation,''~$\psi_{n,t}$, and then hypothesize various models
for how the activation couples across neurons and evolves through time.
For example, factor analysis (FA) corresponds to the hypothesis that the activation is well
modeled as,~$\bpsi_{t} = \bC \bx_t$,
where~$\bx_t$ represents a low dimensional state at time~$t$, and~$\bC$ is a 
linear mapping from latent states to activations. 
Linear dynamical systems (LDS's) extend factor analysis by modeling how the latent 
states evolve over time. Specifically, an LDS assumes,~$\bx_t \sim \bA \bx_{t-1} + \bepsilon_t$, where 
the matrix~$\bA$ specifies the linear dynamics and~$\bepsilon_t$ represents Gaussian noise. 
This captures the temporal correlations in spike counts.
Hidden Markov models (HMM's) characterize population activity in terms of a \emph{discrete}
latent state~${z_t \in \{1, \ldots, K\}}$, each of which corresponds to a different 
activation vector,~$\bpsi^{(k)}$. Then, the instantaneous activation is~$\bpsi_{t}=\bpsi^{(z_t)}$.
This may be an appropriate model for populations that switch between ``on'' and ``off'' states, 
for example. 
Combining HMM's and LDS's, we arrive at a \emph{switching} linear dynamical system (SLDS) model 
with both continuous and discrete latent states. When in discrete state,~$z_t$, 
the continuous state,~$\bx_t$, is governed by dynamics matrix,~$\bA^{(z_t)}$. 
Though the instantaneous dynamics are always linear, switching between these 
discrete latent states allows us to model complex, nonlinear dynamics of the neural population.
From this perspective, it is clear that these seemingly disparate models
correspond to a sequence of nested, increasingly sophisticated hypotheses about
the latent structure underlying neural activity.

When the observed signal is well modeled by a Gaussian distribution, 
the conditional distribution over continuous latent states,~$\bx_t$, is 
Gaussian and can be computed in closed form, and we can leverage a 
host of off-the-shelf inference algorithms. However, when modeling 
discrete spike counts, a Bernoulli, Poisson model is more appropriate. 
In cases where the spike counts are overdispersed, a negative binomial 
model may provide an even better fit. Unfortunately, these discrete models are not 
conjugate with the Gaussian latent states and inference is
considerably more complicated. Substantial work has gone into 
developing approximate inference algorithms for such models \citep{macke2011empirical},
but these methods rely on approximations to the model. 
% The need for model-specific approximations makes it difficult to 
% tweak the model and incorporate additional structure.
Though these approximations are fast and effective in practice, they can yield
asymptotically biased inferences.
Moreover, they often provide only a point estimate of the latent states and
parameters, which does not reveal Bayesian uncertainty estimates or permit
robust model comparison. 
Here, we present a simpler, faster, fully Bayesian set of algorithms that
are easy to compose and extend.


\begin{figure}
\centering
% Top row: \psi's
  \begin{subfigure}[t]{.26\textwidth}
    \centering
    \vskip 0pt
    \includegraphics[height=1.4in]{figures/ch8/pred_ll_best_bar.pdf}
    \label{fig:pred_ll_best}
  \end{subfigure}
  ~
  \hspace{-2em}
  \begin{subfigure}[t]{.46\textwidth}
    \centering
    \vskip 0pt
    \includegraphics[height=1.4in]{figures/ch8/pred_ll_vs_D_bar.pdf}
  \end{subfigure}
  ~
  \begin{subfigure}[t]{.26\textwidth}
    \centering
    \vskip 0pt
    \includegraphics[height=1.4in]{figures/ch8/pred_ll_best_vs_time_D10.pdf}
  \end{subfigure}
  \\
  \begin{subfigure}[t]{\textwidth}
    \centering
    \vskip 0pt
    \includegraphics[width=3.8in]{figures/ch8/pred_ll_legend.pdf}
  \end{subfigure}
  \vspace{-1em}
  \caption[Comparison of state space models on hippocampal data]
  {A comparison of latent state space models (FA, LDS, SLDS,
    and HMM) with either Poisson (P) or negative binomial (NB)
    observations fit by our P\'{o}lya-gamma augmented Gibbs sampler to
    a population recording of hippocampal place cells. We measure
    predictive log likelihood on a heldout subset of spike counts and
    find that negative binomial dynamical systems provide the best
    account (left). The latent state space dimensionality,~$D$, is fit
    by cross validation (center), and as the dimension increases the
    models over-fit the training data. Finally, we compare to a
    Poisson LDS (PLDS) model fit via EM and find that our algorithms
    are comparably fast, especially when~$D$ is large
    (right,~$D=10$).}
  \label{fig:hipp}
\end{figure}


\section{Bayesian Inference with \polyagamma Augmentation}
% TODO: Edit the text to reduce overlap with Finale submission!
\polyagamma augmentation is an auxiliary variable scheme that allows
logistic likelihoods to appear as Gaussians.  This
scheme has recently been used to develop Gibbs sampling and
variational inference algorithms for Bernoulli, binomial, 
negative binomial, and multinomial regression models
with logit link functions \citep{polson2013bayesian}.
Here, we use the augmentation strategy to
develop efficient Markov transition operators for the 
intermediate distributions encountered in annealed importance sampling.

The \polyagamma augmentation is based on an integral identity
derived from the Laplace transform of the \polyagamma distribution. 
Specifically, if $p_{\distPolyaGamma}(\pgvar\given b, 0)$ is the density of
the \polyagamma distribution~${\distPolyaGamma(b, 0)}$, then
\begin{equation}
\frac{(e^{z})^a}{(1+e^{z})^b} = \int_{0}^{\infty} 2^{-b} e^{\kappa z}  e^{-\pgvar z^2 /2} \, p_{\distPolyaGamma}(\pgvar \given b, 0) \, \mathrm{d}\pgvar,
\label{eq:pg_identity}
\end{equation}
where~${\kappa=a-b/2}$. The integral on the right-hand side is the
Laplace transform of the \polyagamma density evaluated at~$z^2/2$,
and the left-hand side is the same form found in
the intermediate distributions of Eq.~\ref{eq:intermediate}.  Importantly, viewed as a function of~$z$ for
fixed~$\pgvar$, the right-hand side is an unnormalized Gaussian
density.  Thus, the identity in equation~\ref{eq:pg_identity}
transforms a logistic likelihood to a Gaussian likelihood conditioned on an
auxiliary variable,~$\pgvar$. 

We employ this augmentation scheme to sample the intermediate
distributions,~$f_t(\theta, \bz)$, by plugging the
integral identity in Eq.~\ref{eq:pg_identity} into the likelihood
of Eq.~\ref{eq:intermediate}. We augment each observation
with an \polyagamma distributed auxiliary variable~$\pgvar_n$.
Given these auxiliary variables, the conditional distribution of~$\bz$ is Gaussian,
\begin{align}
  \label{eq:f_t}
  f_t(\bz \given \theta, \bpgvar) &\propto \distNormal(\bz \given \bJ_\theta, \bh_\theta) \,
  \prod_{n=1}^N e^{\kappa(x_n, \theta) \beta_t z_n - \pgvar_n z_n^2 /2} \\
  &\propto \distNormal(\bz \given \bJ_\theta, \bh_\theta) \,
  \distNormal \left(\bz \given \bcappgvar, \, \bkappa(\bx, \theta) \,\beta_t \right) \\
  &\propto \distNormal \left(\bz \given \bJ_\theta + \bcappgvar,\,
  \bh_\theta + \bkappa(\bx, \theta) \,\beta_t \right)
\end{align}
where~${\bcappgvar = \text{diag}([\pgvar_1, \ldots, \pgvar_N])}$, and
the vector~${\bkappa(\bx, \theta)}$ has entries~
${\kappa(x_n, \theta) = a(x_n, \theta) - b(x_n, \theta)/2}$.
When~${\beta_t \to 0}$, the second parameter reduces to its prior,~$\bh_\theta$.
As we will show next, the auxiliary variables will also go
to zero, causing the precision to reduce to its prior value as well.

By the exponential tilting property of the \polyagamma
distribution, the conditional distribution of~$\pgvar_n$
is proportional to a \polyagamma distribution:
\begin{align*}
  \nonumber
  f_t(\pgvar_n \given z_n, x_n, \theta) &
  \propto e^{-\pgvar_n z_n^2/2}
  p_{\distPolyaGamma}(\pgvar_n \given b(x_n, \theta) \cdot \beta_t, \, 0) \\
  &\propto p_{\distPolyaGamma}(\pgvar_n \given b(x_n, \theta) \cdot \beta_t, \, z_n).
\end{align*}
When the shape parameter,~$b(x_n, \theta) \cdot \beta_t$, goes to zero, the
\polyagamma density reduces to a delta function at zero. 

In many cases, the functions in the exponent,~$a(\cdot)$ and~$b(\cdot)$,
will be independent of~$\theta$, in which case we can update theta
as we would for the standard model. The main exception is the
negative binomial likelihood,~$x_n \sim \distNegBinomial(\theta, \sigma(z_n))$,
where~$\theta$ is the unspecified ``number of failures.''
In this case,~$\theta$ is scalar and can be sampled using a number
of general purpose techniques like slice sampling.

Thus, our proposed transition operators,~$\mcT_t$, perform three steps, 
\begin{enumerate}
\item sample~$\bz$ from its Gaussian conditional distribution;
\item sample~$\theta$ from its conditional; and
\item sample all~$\pgvar_n$ in parallel from their \polyagamma conditional distributions.
\end{enumerate}



\section{Results}
First, we studied a population of 47 hippocampal place cells recorded from a freely moving rat in a 
circular arena.\footnote{Data courtesy of the Wilson lab at MIT.} Spikes were counted in 
250ms bins for approximately ten minutes.
 We held out half of the spike counts (randomly sampled) to compute the predictive 
likelihood of each model relative to a constant-rate Poisson model baseline. 
Figure~\ref{fig:hipp} shows the results of our comparison for a negative binomial model with constant 
activation and FA, HMM's, LDS's, and switching LDS's with both Poisson and negative binomial observations,
all fit using our augmented MCMC inference algorithm.  We found that the simple FA models over-fit the 
training data and performed poorly on generalization tasks. HMMs, which 
have no low dimensional continuous latent state to tether neurons together, 
performed even worse on predictive tasks. By contrast, the LDS and SLDS 
models and SLDS models exploited temporal dynamics in order to inform latent state estimates.
We explored the effect of the latent state space dimensionality (center panel) and found that 
the LDS and SLDS models generalized well with 4 to 6 dimensional latent states. 
In all cases, the negative binomial 
observation models provided a better fit to the data, suggesting that these 
spike counts were indeed overdispersed (i.e. had variance larger than the mean). With 
our framework, fitting a negative binomial model requires simply changing the 
coefficients of the observation model.

We also compared to a Poisson LDS fit via EM, following \citep{macke2011empirical},
and found that predictive log likelihood estimates with state sequences drawn from 
their variational posterior yield poor predictive estimates. For this dataset, samples 
from our true, non-Gaussian posterior yield more accurate results. Contrary 
to common beliefs about MCMC, our inference algorithms are able to 
explore the posterior parameter space with block Gibbs updates and achieve performance 
that is comparable to EM algorithms, which must solve a large convex optimization problem 
at each iteration (right panel).

Our Bayesian treatment of latent state space models provides a unified 
framework for composing and comparing models of neural activity, and 
identifying latent structure underlying spike trains. As shown with
hippocampal recordings, adopting such an approach allows us to find
a parsimonious description of the neural activity quickly and efficiently
in models that traditionally pose significant inferential challenges.



\section{Marginal Likelihood Estimation}
The marginal likelihood of a model,~$\mcM$, is the probability of the
data,~$\bx$, having integrated out the latent
variables,~$\bz$, and parameters,~$\theta$, of the model:
\begin{align*}
  {p(\bx \given \mcM) = \int p(\bx \given \bz, \theta) \, p(\bz, \theta
  \given \mcM) \, \mathrm{d} \bz \, \mathrm{d}\theta}
\end{align*}
By integrating over the latent variables and parameters, the marginal
likelihood captures a tradeoff between a model's complexity and its
ability to explain the data.  As such, it is a natural criterion for
model comparison. For conjugate exponential family 
models, like linear Gaussian models with Gaussian observations,
 the marginal likelihood can be computed in closed form. 
In these cases, marginal likelihood is often the gold-standard 
for model selection \cite{kass1995bayes}.

Unfortunately, minor adjustments to the model can render the
integration over parameters and latent variables intractable.  For
example, the marginal likelihood is intractable for models with latent
Gaussian structure, like Gaussian processes or linear dynamical
systems, and non-Gaussian observations, like discrete counts.
Instead, we are forced to resort to approximate methods like annealed
importance sampling (AIS) \cite{neal2001annealed}.  AIS is based on
sampling from a sequence of intermediate distributions that
\emph{anneal} between a tractable distribution and the intractable
posterior. While AIS has proven highly effective for a variety of
models \cite{grosse2015sandwiching}, the accuracy of the method hinges
upon the efficiency of the Markov transition operators that target
the intermediate distributions.  Unfortunately, these distributions
often lack exploitable structure present in the posterior, making the
design of efficient transition operators challenging, and ultimately
compromising the efficacy of AIS.

In this work, we develop efficient transition operators that make AIS
simple and efficient for a broad class of models: those in which the
latent variables are Gaussian distributed, the data are discrete, and
the link is provided by a logistic function. Formally, we consider
models of the form,
\begin{align*}
p(\bx, \bz, \theta) 
&= p(\theta) \, \distNormal(\bz \given \bJ_\theta, \bh_\theta) \prod_{n=1}^N p(x_n \given z_n, \theta),
\end{align*}
where the likelihood can be written,
\begin{align*}
\nonumber  p(x_n \given z_n, \theta) &= c(x_n, \theta) \, \sigma(z_n)^{a(x_n, \theta)} \, (1-\sigma(z_n))^{d(x_n, \theta)} \\
  &= c(x_n, \theta) \frac{(e^{z_n})^{a(x_n, \theta)}}{(1+e^{z_n})^{b(x_n, \theta)}}.
\end{align*}
We call these \emph{logistic likelihoods} because the latent variables
are transformed by a logistic function,~${\sigma(z)=e^z /(1+e^z)}$.
Bernoulli, binomial, negative binomial, and multinomial likelihoods
are all in this class.

We have written the Gaussian prior in information form,
\begin{align*}
  \distNormal(\bz \given \bJ_\theta, \bh_\theta) &\propto \exp \left \{-\frac{1}{2} \bz^\trans \bJ_\theta \bz + \bh_\theta^\trans \bz \right\}, 
\end{align*}
which can be related back to the standard form by the
transformations,~$\Sigma = J^{-1}$ and~$\mu = J^{-1}h$.  The Gaussian
prior encapsulates a host of well-known models, like factor analysis,
sparse linear models, Gaussian processes, and linear dynamical
systems, as we will highlight in our applications below.

We begin by reviewing annealed importance sampling and the \polyagamma
augmentation scheme, which we will leverage to develop efficient
transition operators. Section~\ref{sec:pgsampling} derives a
novel sampling algorithm for the \polyagamma distribution --
the main technical contribution of this paper. The remaining
sections illustrate the practical import of this development
by demonstrating significant improvements in marginal likelihood
estimation for a variety of real-world modeling problems.


\subsection{Annealed Importance Sampling}

Annealed importance sampling \cite{neal2001annealed} is a method of
estimating the marginal likelihood,~$p(\bx)$, by ``annealing'' between
a tractable distribution, with known normalization constant, and the
joint distribution, whose normalization constant is the marginal
likelihood of interest. The annealing path is a sequence of
distributions,~${p_1(\theta, \bz), \ldots, p_T(\theta, \bz)}$,
where~${p_t(\theta, \bz)=f_t(\theta, \bz)/\mcZ_t}$,
and~${f_T(\theta, \bz) =p(\theta, \bz, \bx)}$, such that~${\mcZ_T=p(\bx)}$.
Typically, we let~$f_1(\theta, \bz)$ be the normalized prior
distribution such that~${\mcZ_1=1}$. Then, we let~$f_t(\bz, \theta)$ be
a geometric average of the prior and the joint:
\begin{align*}
  f_t(\theta, \bz) &= p(\theta, \bz) \, p(\bx \given \bz, \theta)^{\beta_t},
\end{align*}
with~$\beta_t$ monotonically increasing from~${\beta_1=0}$ to~${\beta_T=1}$.

Given this annealing path, we can generate a sample of~$(\theta,
\bz)$ by first sampling from the prior, and then applying a sequence
of MCMC transition operators~$\mcT_t$ that leave the intermediate
distributions~$p_t$ invariant. The result is a sample that is,
hopefully, closer in distribution to the posterior. We can use
this procedure as a proposal distribution for importance sampling.
The importance weights are given by a product of ratios between~$f_t$ and~$f_{t-1}$.
Since the target density is the unnormalized joint distribution,
the importance weights will be unbiased estimates of the normalization
constant, namely the marginal likelihood,~${\mcZ_T =p(\bx)}$.

How can we reduce the variance of this estimator? First, we can
increase the number of intermediate distributions; second, we can
design rapidly mixing transition operators,~$\mcT_t$. In this work,
we develop transition operators that are both computationally efficient,
allowing us to run more transitions in a fixed amount of time, and more
effective, in that they quickly reach their equilibrium distribution.

With a geometric annealing path, the intermediate distributions are given by,
\begin{align}
  \label{eq:intermediate}
  f_t(\theta, \bz) 
  &= p(\theta) \, \distNormal(\bz \given \bJ_\theta, \bh_\theta) \,  
    \prod_{n=1}^N c(x_n, \theta)^{\beta_t} \frac{(e^{z_n})^{a(x_n, \theta) \cdot \beta_t}}
    {(1+e^{z_n})^{b(x_n, \theta) \cdot \beta_t}}.
\end{align}
There is no immediate conjugacy that we can exploit in order to design
MCMC transition operators for these distributions, but by clever
augmentation, we can derive efficient updates.

However, for this transition to be efficient, 
we must be able to sample from the \polyagamma 
conditional distribution in the regime where~${b(x_n, \theta) \cdot \beta_t < 1}$.
For Bernoulli observations,~${b(x_n, \theta) \equiv 1}$, so we
will be in this regime for all~$\beta_t \in [0,1)$.
While efficient samplers exist for \polyagamma distributed variables 
when the shape parameter is greater than one \citep{windle2014sampling}, 
this ``small shape'' regime has not been previously explored.
We develop a novel sampling algorithm that makes these 
conditional updates extremely efficient, and renders AIS with 
\polyagamma augmented transitions highly effective.

\section{A Novel Sampling Algorithm for the \polyagamma Distribution}
\label{sec:pgsampling}

\begin{figure}
\centering
  \begin{subfigure}[t]{3in}
    \centering
    \vskip 0pt
    \includegraphics[width=\textwidth]{figures/ch8/psi}
  \end{subfigure}
  \\
  \begin{subfigure}[t]{3in}
    \centering
    \vskip -2em
    \includegraphics[width=\textwidth]{figures/ch8/acceptance}
  \end{subfigure}
  \vspace{-1em}
  \caption[Rejection sampling algorithm for the \polyagamma
    distribution] {\textit{Top:} Plot of~$\Psi(\pgvar \given b)$, the
    conditional acceptance probability for a proposed value
    of~$\pgvar$, for~$b\in (0,1]$. In all cases, this function is
  monotonically increasing from 0 to 1 as a function of~$\pgvar$, and
  thus defines a cumulative distribution function.  \textit{Bottom:}
  Acceptance probability,~$\alpha(b,z)$, as a function of~$b$
  and~$z$.}
\label{fig:pgsampling}
\end{figure}

The \polyagamma distribution,~$\distPolyaGamma(b,z)$, is closely related 
to the Jacobi distribution,~$\distJacobi(b,z)$, surveyed by \citet{biane2001probability} and 
defined in~\citet{windle2014sampling}.
Specifically, ${\distPolyaGamma(b, z) \sim \frac{1}{4} \distJacobi(b, \tfrac{z}{2})}$.
Thus, to develop a sampler for the \polyagamma distribution, 
it is sufficient to be able to sample the Jacobi distribution.

The density of~$\distJacobi(b,z)$ can be written as an infinite alternating sum,
\begin{multline*}
  p_{\distJacobi}(\pgvar \given b, z) = \\ 
  \cosh^b(z) e^{-\pgvar z^2/2} \frac{2^b}{\Gamma(b)} 
  \sum_{n=0}^\infty (-1)^n \frac{\Gamma(n+b)}{\Gamma(n+1)} \frac{(2n+b)}{\sqrt{2\pi \pgvar^3}}
  \exp\left\{- \frac{(2n+b)^2}{2\pgvar} \right\}.
\end{multline*}
This can be factored as follows,
\begin{align*}
  % \nonumber &p_{\distJacobi}(\pgvar \given b, z) \\
  % \nonumber &\quad= \cosh^b(z) \frac{b 2^b}{\sqrt{2\pi \pgvar^3}} 
  %   \exp \left \{ -\frac{b^2}{2\pgvar} - \frac{\pgvar z^2}{2} \right \}
  %   \Psi(\pgvar \given b) \\
  % &= \cosh^b(z) \frac{b 2^b}{\sqrt{2\pi \pgvar^3}} 
  %   \exp \left \{ -\frac{z^2}{2\pgvar} \left[\left( \frac{b}{z} \right)^2 + \pgvar^2 \right]\right \}
  %   \left( 1-\Psi(\pgvar \given b) \right) \\
  % &= \cosh^b(z) \frac{b 2^b}{\sqrt{2\pi \pgvar^3}} 
  %   \exp \left \{ -\frac{z^2}{2\pgvar} \left[\left( \pgvar- \frac{b}{|z|} \right)^2  +\frac{2b\pgvar}{|z|}\right]\right \}
  %   \left( 1-\Psi(\pgvar \given b) \right) \\
  %&= \cosh^b(z) \frac{b 2^b}{\sqrt{2\pi \pgvar^3}} 
  %  \exp \left \{ -\frac{\left(\tfrac{|z|}{b}\right)^2 b^2}{2\pgvar} \left( \pgvar- \frac{b}{|z|} \right)^2  
  %  -b|z| \right \} 
  %  \left( 1-\Psi(\pgvar \given b) \right) \\
  % &\quad = 2^b \, \cosh^b(z) \, e^{-b|z|} \,
  %   p_{\distInvGaussian} \left(\pgvar \, \bigg| \, \frac{b}{|z|}, \, b^2 \right) 
  %   \Psi(\pgvar \given b),
  p_{\distJacobi}(\pgvar \given b,z) &= 
   \alpha^{-1}(b,z) \,
   p_{\distInvGaussian}\left(\pgvar \, \bigg| \, \frac{b}{|z|}, \, b^2 \right) \,
   \Psi(\pgvar \given b),
\end{align*}
where~$\alpha^{-1}(b,z)$ is a scaling constant greater than one,
\begin{align*}
  \alpha^{-1}(b,z) = 2^b \, \cosh^b(z) \, e^{-b|z|} 
  % &= 2^b \cosh^b(|z|) \, e^{-b|z|} \\
  % &= 2^b \left(\frac{(1+e^{-2|z|}) e^{-|z|}}{2e^{-|z|}} \right)^b \\
  = \left(1 + e^{-2|z|} \right)^b \geq 1;
\end{align*}
where~$p_{\distInvGaussian}(\cdot)$ denotes the inverse Gaussian density,
\begin{align*}
p_{\distInvGaussian} \left(\pgvar \, \bigg| \, \frac{b}{|z|}, \, b^2 \right) 
  % &= \left( \frac{b^2}{2\pi \pgvar^3} \right)^{1/2} 
  %   \exp \left \{ - \frac{b^2 \left(\pgvar - \tfrac{b}{|z|} \right)^2}{2 \left(\tfrac{b}{|z|} \right)^2 \pgvar}   \right \} \\
  &= \frac{b}{\sqrt{2\pi \pgvar^3}}
    \exp \left \{ - \frac{z^2}{2\pgvar}  \left(\pgvar - \frac{b}{|z|} \right)^2   \right \};
\end{align*}
and where we have defined~$\Psi(\pgvar \given b)$ as,
\begin{align*}
  \Psi(\pgvar \given b)  
  &= \sum_{n=0}^\infty (-1)^n \frac{\Gamma(n+b)}{\Gamma(n+1)} \frac{2n+b}{\Gamma(b+1)}
    \exp\left\{- \frac{2n(n+b)}{\pgvar} \right\}.  
\end{align*}
Figure~\ref{fig:pgsampling} plots~$\Psi(\pgvar \given b)$ for various values of~$b$.
% , and shows that it is bounded to the range~$[0,1]$.
Since~$\alpha^{-1}(b,z)\geq 1$ and~$\Psi(\pgvar \given b) \in [0,1]$,
we are guaranteed that~${\alpha^{-1}(b,z)\,
  p_{\distInvGaussian}(\pgvar \given \tfrac{b}{|z|}, b^2)}$
dominates~$p_{\distJacobi}(\pgvar \given b,z)$, which makes the
inverse Gaussian a natural proposal distribution for a rejection
sampling algorithm.  To determine whether a proposed value of~$\pgvar$
is accepted, we must sample~$u \sim \mathrm{Unif}(0,1)$, and check
whether~$u < \Psi(\pgvar \given b)$.
% This is sometimes referred to
% as \emph{generalized rejection sampling}~\cite{devroye1986}.

The acceptance probability is~$\alpha(b,z)$, the inverse of the
scaling constant. It is bounded
between~$[\tfrac{1}{2}, 1]$ when~$b \leq 1$.
The lower bound (worst case) is achieved when~$z=0$ and~$b=1$.
The upper bound (best case) is approached as~$b$ goes to zero or~$|z|$ goes 
to infinity.
This is illustrated in Figure~\ref{fig:pgsampling} for a 
range of~$b$ and~$z$.

Determining acceptance requires a comparison against~$\Psi(\pgvar
\given b)$, for given~$\pgvar$ and~$b$. This function is not
analytically tractable, however, it is still possible to determine
whether or not to accept with finite computation. To do so, we use a
slight modification of the \emph{alternating series method}
\cite{devroye1986}.  We exploit the fact that ~$\Psi(\pgvar \given b)$
is an alternating sum, and the absolute value of the terms is
eventually monotonically decreasing as a function of the index~$n$ for
all fixed values of~$b$ an~$z$.  Thus, after we have computed the
increasing terms, all subsequent partial sums for even~$n$ are upper
bounds, and all subsequent partial sums for odd~$n$ are lower bounds
on~$\Psi(\pgvar\given b)$.  To determine acceptance of~$u$, we
evaluate until we find an upper bound less than~$u$, at which point we
reject, or a lower bound greater than~$u$, at which point we
accept. This is typically done in fewer than six iterations. 
