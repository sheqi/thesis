Neuroscience is entering an exciting new age.  Modern recording
technologies enable simultaneous measurements of
thousands of neurons in organisms performing complex behaviors.  Such
recordings offer an unprecedented opportunity to glean insight into
the mechanistic underpinnings of intelligence, but they also present
extraordinary statistical and computational challenges.
This thesis develops a suite of tools that instantiate
hypotheses about neural computation in the form of
probabilistic models and a corresponding set of Bayesian inference
algorithms that efficiently fit these models to neural spike trains.
From the posterior distribution of model parameters and variables,
we seek to advance our understanding of how the brain works. 

At the core of these probabilistic models is a collection of
structural motifs such as random network models and dynamic latent states. The
persistent challenge lies in reconciling these models with the
discrete nature of neural spike trains.  Our principal tool for
connecting structure and spike trains is the Hawkes process, a
multivariate generalization of the Poisson process.  By
leveraging the linear nature of these processes and the Poisson
superposition principle, we derive elegant auxiliary variable
formulations and efficient inference algorithms. We then generalize
these to nonlinear and nonstationary models of neural spike trains and
take advantage of the \polyagamma augmentation to develop novel
Markov chain Monte Carlo (MCMC) inference algorithms.

In the latter chapters, we shift our focus from autoregressive models
to latent state space models of neural activity. We provide an
empirical study of Bayesian nonparametric methods for hidden Markov
models of neural spike trains. Then, we develop an MCMC algorithm for switching
linear dynamical systems with discrete observations and a novel
algorithm for sampling \polyagamma random variables that enables 
efficient annealed importance sampling for model comparison.

Finally, we consider the ``Bayesian brain'' hypothesis --- the
hypothesis that neural circuits are themselves performing Bayesian
inference.  We show how one implementation of this
hypothesis implies autoregressive dynamics, thereby providing a theoretical interpretation of
our probabilistic models.  This closes the
loop, connecting top-down theory with bottom-up inferences, and
suggests a path toward translating large scale recording
capabilities into new insights about neural computation.


