%\begin{savequote}[75mm]
% The idea that complex physical, biological or sociological systems can be exactly described by a few formulae is patently absurd. The construction of idealized representations that capture important stable aspects of such systems is, however, a vital part of general scientific analysis...
%\qauthor{Sir David Cox}
%\end{savequote}

\chapter{Background}
This chapter lays the foundation for those that follow by introducing 
the essential toolkit of probabilistic modeling: the language of 
generative models, the building blocks of time series, and the algorithms
of Bayesian inference. 


\section{Generative Probabilistic Models}
\label{sec:generative_models}
Generative probabilistic models formalize a story of how data comes to be. 
While this story never captures every physical detail, it serves as an 
idealized version that captures the essence of the system. For example, when
modeling a neural spike train, we will ignore the states of individual ion 
channels and the nonlinear dynamics of membrane potential and instead 
characterize the instantaneous \emph{firing rate} of a neuron --- the 
probability that a neuron spikes at any moment in time. 

As a simple illustration, consider the following generative
process. Suppose a neuron has two states, an \emph{up} state and an
\emph{down} state. In the \emph{up} state, the neuron spikes at a high
rate, say 100Hz, and in the \emph{down} state it rarely fires, say at 1Hz.
Assume that every 50ms the neuron flips a coin to decide what state it
will be in, and then fires a random number of spikes according to the
rate associated with its current state. Once 50ms have elapsed, it
flips another coin and its rate immediately changes to reflect its new
state. Moreover, assume that all we observe is the number of spikes
fired in each 50ms time bin.  Our goal is to infer the latent state of
the neuron given the observed spike counts.

Clearly, this generative story contains many simplifying assumptions
and omits a great amount of detail. In addition to assuming that
spiking is adequately captured by firing rates, the notion that a
neuron has only two firing rates and that it randomly switches between
them is obviously a gross simplification. Nevertheless, this very
simple model captures some patterns of spiking that have been observed
in experiment \cite{cowan1994spontaneous, shu2003turning}. 

\sloppy We can formalize this generative story with a probabilistic
model that specifies a joint distribution over latent states and
observed spike counts. Let~$s_t \in \naturals$ denote the number of
spikes counted in the~$t$-th time bin,
and~$z_t \in \{\textit{up}, \textit{down}\}$ denote the corresponding
state of the neuron. The assumption that states are drawn from a coin
flip corresponds to the prior distribution,
${z_t \sim \distBernoulli(\rho)}$, where~$\rho$ specifies the
probability of \textit{up} versus \textit{down} states.  Implicitly,
we assumed that~${\rho=\tfrac{1}{2}}$, though this need not be the
case.  We previously said that the neurons fire a random number of
spikes according to their state-dependent firing rate; now we will
formalize this by
assuming,~${s_{t} \sim \distPoisson(\lambda_{z_t} \cdot \Delta t)}$,
where ${\Delta t = 0.05\text{s}}$,
${\lambda_{\textit{up}} = 100\,\text{spikes/s}}$, and
${\lambda_{\textit{down}} = 1\,\text{spike/s}}$. 
The joint distribution 
is,
\begin{align}
  \label{eq:joint_chain_rule}
  %p(\bs, \bz \given \rho, \lambda_{\textit{up}}, \lambda_{\textit{down}}, \Delta t) 
  %&= p(\bz \given \rho) \, p(\bs \given \bz, \lambda_{\textit{up}}, \lambda_{\textit{down}}, \Delta t) \\
  p(\bs, \bz \given \rho, \blambda, \Delta t) 
  &= p(\bz \given \rho) \, p(\bs \given \bz, \blambda, \Delta t) \\
  \label{eq:joint_factorized}
  &= \prod_{t=1}^T p(z_t \given \rho) \, p(s_t \given \lambda_{z_t}, \Delta t) \\
  &= \prod_{t=1}^T \distBernoulli(z_t \given \rho) \, \distPoisson(s_t \given \lambda_{z_t} \cdot \Delta t).
\end{align} 
Here, we have introduced notation that will be used throughout this
thesis. Bold symbols like~$\bs$ will denote arrays of
random variables. Typically, lowercase bold symbols will denote
vectors, as in this case,~${\bs = \big[s_1, \ldots, s_T \big]}$ 
and~${\blambda = \big[ \lambda_{\textit{up}}, \lambda_{\textit{down}} \big]}$.

In addition to specifying functional forms for the distributions,
${p(z_t \given \rho)}$ and~${p(z_t \given \lambda_{z_t}, \Delta t)}$,
the probabilistic model also formalizes the particular factorization of
the joint probability distribution implied by the generative story.
Eq.~\ref{eq:joint_chain_rule} simply applies the chain rule of
probability, which does not reflect any loss of generality. However,
in going from \eqref{eq:joint_chain_rule} to
\eqref{eq:joint_factorized}, we have asserted that the latent
states~$z_t$ and~$z_{t'}$ are conditionally independent given~$\rho$,
and that the spike counts~$s_{t}$ and~$s_{t'}$ are conditionally
independent given their corresponding latent states. This conditional
independence assumption, which was implicit in the generative story,
is made explicit when we factor the joint distribution into a product
over time bins. When we hypothesize relationships between different variables,
we are making assertions about the factorization of the joint distribution. 
In Section~\ref{sec:motifs}, different patterns of conditional dependence 
that form the building blocks of models for dynamic data.

% Latent variables (states at each time)
% Parameters rates associate with each state
% Prior distributions on parameters
The model above assumes that the firing rates are known, but in practice 
this is a bit unreasonable. A more reasonable hypothesis is that neurons have 
two firing rates, and while we do not know their exact values, we can 
specify a distribution over them. To keep the model simple, let's assume 
that the firing rates are both drawn from the same prior, 
${\lambda_{*} \sim \distGamma(\alpha, \beta)}$. Similarly, we may not know 
the exact probability of each state,~$\rho$, but we can place a reasonable
 prior distribution on it, for instance, ${\rho \sim \distBeta(\tau_0, \tau_1)}$.
Incorporating these prior distributions into the model yields the joint 
distribution,
\begin{align}
  \label{eq:full_joint}
  p(\bs, \bz, \rho, \blambda \given \alpha, \beta, \tau_0, \tau_1, \Delta t) 
  &= p(\rho \given \tau_0, \tau_1) \, 
     p(\blambda \given \alpha, \beta) \,
     p(\bs, \bz \given \rho, \blambda, \Delta t).
\end{align}

We will often distinguish between the different types of random
variables in the model. The states,~$\bz$, are called \emph{latent
  variables} because their number grows with the size of the dataset,
in this case there is one latent state per time bin. The latent state
probability,~$\rho$, and the firing rates,~$\blambda$, are called
\emph{parameters} because there are a fixed number of them. The
remaining values,~${\{ \alpha, \beta, \tau_0, \tau_1, \Delta t \} }$,
are called \emph{hyperparameters}. These are constants that we set
prior to performing inference.  Typically, these can be tuned
cross-validation, or simply set based on intuition and physical
constraints.

\subsection{Representations of Spike Trains}
% Notation for sets of spike times or spike count matrices
As modelers, one of the first decisions we must make is how we
represent our data. In this thesis we will focus solely on modeling
spike trains, which are sequences of discrete events in time. These
spike trains typically come from spike sorting algorithms applied to
extracellular recordings from multi-electrode arrays
\cite{lewicki1998review, quiroga2004unsupervised}, or from
deconvolution algorithms applied to optically recorded calcium
fluorescence traces \cite{pnevmatikakis2016simultaneous,
  vogelstein2010fast}. Reducing the data to the set of spikes often 
results in an enormous compression. Rather than considering electrode 
potentials, which are often sampled at upwards of 10kHz, or calcium 
fluorescence traces, which are highly autocorrelated due to the relatively 
slow dynamics of calcium concentration in cells, we can instead consider 
only the times of action potentials.

While this thesis treats the spike trains as given, it is also possible to
work directly with the observed extracellular recordings or calcium
fluorescence and treat the spike train as a latent variable.  Then,
the spike train must be inferred along with the rest of the model's
latent variables and parameters, cf. \cite{pillow2013model}. As we just 
mentioned, this will typically incur a substantial cost, but it may be 
worthwhile if there is considerable uncertainty in the spike timing 
and if precise timing is important to the overarching model.

The most general representation of a spike train is as a set of~$M$
\emph{marked} spike times.
Let,
\begin{align}
  \mcS = \left \{ (s_m, c_m) \right \}_{m=1}^M \subset [0, T] \times \{1, \ldots, N\}.
\end{align}
Each member of this set consists of a real-valued spike time~$s_m$ in
the interval~$[0, T]$, and an integer,~$c_m \in \{1, \ldots, N\}$,
that specifies the index of the cell that generated this spike. 
% In the working example of a neuron with an \emph{up} and \emph{down}
% state there is only one neuron ($N=1$), so the cell markers would be
% trivially equal to~$c_m=1$.
This continuous-time representation is
warranted when the temporal resolution of the data is considerably
higher than the timescale of typical action potentials. For example,
multielecrode arrays typically have sampling intervals of~$0.1$ms or
smaller, whereas the width of action potentails is on the order
of~$1$ms. This allows us to specify the spike time as an effectively
real-valued number.  
% Calcium imaging methods typically have much lower temporal
% resolution and are often sampled at lower rates, but by deconvolving
% spike trains it may be possible to obtain effectively higher
% resolution than the raw data affords.

We typically model sets of discrete events like these as realizations
of a \emph{marked point process} \cite{daley2003introduction1}. Such a
process is defined by its firing rates\footnote{In the point process
  literature, these firing rates are called \emph{conditional
    intensity functions}.},
${\{\lambda_n(t \given \mcH_t)\}_{n=1}^N}$, where $\mcH_t$ captures
the history of the process through time~$t$. For example, the history
may include the previous spikes,~${\mcH_t = \{(s_m, c_m): s_m < t\}}$,
or some external covariates,~$x(t)$.  If we consider a small time
window,~${[t, t+\Delta t)}$, and take the limit as~$\Delta t$
approaches zero, the expected number of spikes fired by neuron~$n$ in
the window~${[t, t+\Delta t)}$
is~${\lambda_n(t \given \mcH_t) \cdot \Delta t}$. Our
goal is then to specify flexible and interpretable conditional intensity
functions. Chapter~\ref{chap:hawkes} 

The limiting perspective on the conditional intensity functions
suggestions an alternative, discrete-time representation.  Rather than
modeling a set of continuous spike times and conditional firing rates,
we may instead represent a spike count matrix,~$\bS$, and the
corresponding rate matrix,~$\bLambda$, where,
\begin{align}
  \bS &= 
        \begin{bmatrix}
          s_{1,1} & \cdots & s_{1,N} \\
          & & \\
          \vdots  &        & \vdots  \\ 
          & & \\
          s_{T,1} & \cdots & s_{T,N}
        \end{bmatrix}, 
  & & &
  \bLambda &= 
        \begin{bmatrix}
          \lambda_{1,1} & \cdots & \lambda_{1,N} \\
          & & \\
          \vdots  &        & \vdots  \\ 
          & & \\
          \lambda_{T,1} & \cdots & \lambda_{T,N}
        \end{bmatrix}.
\end{align}
Here,~$s_{t,n} \in \naturals$ denotes the number of spikes fired in
the~$t$-th time bin by the~$n$-th neuron, and~$\lambda_{t,n}$ denotes 
the corresponding firing rate. Sometimes, the effects we
are interested in studying occur at relatively slow time scales, so
discretizing may provide valuable compression while retaining most of
the relevant information. For example, if we are studying neural
dynamics on the order of minutes, then simply knowing how many spikes
occurred each second may provide most of the relevant information, while
precise spike timing may be superfluous.

However, the primary reason to discretize spike times into a matrix of
counts is that the statistics and machine learning community have
developed a much broader set of models for matrices than for sets of
continuous time events.  In the next section, we will explore a number
of common modeling motifs that can be applied to time series data
represented as matrices, and many of the chapters of this thesis will
focus on extending these motifs in novel ways.


\subsection{Motifs of Time Series Models}
\label{sec:motifs}
The art of probabilistic modeling is in balancing conflicting concerns:
our model should capture as much of the relevant structure in the data 
as possible, drawing on our intuition and our existing knowledge of the 
system, yet at the same time we wish to limit the complexity of the model
so that we may perform inference efficiently. One of the ways that we 
accomplish this balancing act is by composing our model out of common,
well-studied motifs. 

\paragraph{Mixture Models}
% Discrete latent states
Our working example from Section~\ref{sec:generative_models}
illustrates one such motif --- a simple mixture model.  The firing
rate takes assumes only two values, and the observed spike counts are
a mixture of counts drawn from the \textit{up} state and counts from
the \textit{down} state. We can easily extend this to populations of
neurons and mixtures of more than two states.  Suppose there are
now~$K$ states, such that~${z_t \in \{1, \ldots, K\}}$. Furthermore,
we generalize the rates~$\lambda_{\textit{up}}$
and~$\lambda_{\textit{down}}$, to vectors of rates, one for each
neuron and state.
Let,~${\blambda_k = \big[ \lambda_{1,k}, \ldots, \lambda_{N,k}\big]}$,
denote a vector of rates where $\lambda_{n,k}$ is the firing rate of
the~${n\text{-th}}$ neuron in state~$k$.  We can write the full rate
matrix,~$\bLambda$, as the outer product of a ~${T \times K}$
indicator matrix,~$\bZ$, and an~${N \times K}$ rate
matrix,~$\bC$. Let~$\be_k$ denote a length-$K$ column vector that is all zero
except for a single one in the~$k$-th position.
Then,~${\bLambda = \bZ \bC^\trans}$, where,
\begin{align}
  \bZ = 
        \begin{bmatrix}
          - & \be_{z_1}^\trans & - \\
            &                  &   \\
            &  \vdots          &   \\
            &                  &   \\
          - & \be_{z_T}^\trans & - 
        \end{bmatrix}, 
  \qquad
  \bC = 
        \begin{bmatrix}
          | &  & | \\
          \blambda_1 & \cdot \cdot & \blambda_K \\
          | &  & | 
        \end{bmatrix}.
\end{align}
Now that we have framed the mixture model as a simple factorization of 
the rate matrix, a number of connections and extensions become clear.

\paragraph{Hidden Markov Models}
% Autoregressive latent states
First, the mixture model encodes the hypothesis that the latent states
are independent from one time to the next.
Hence,~$p(\bz)=\prod_{t} p(z_t)$.  Instead, it is natural to expect
the latent states to exhibit some temporal dynamics. For example, we
may hypothesize that the states obey a Markov process such that,
\begin{align}
  p(\bz \given \bpi, \bA) &= p(z_1 \given \bpi) \prod_{t=2}^T p(z_t \given z_{t-1}, \bA) \\ 
  \label{eq:hmm}
  &= \distCategorical(z_1 \given \bpi) \prod_{t=2}^T \distCategorical(z_t \given \bA^\trans \be_{z_{t-1}}),
\end{align}
where~$\bpi \in [0,1]^K$ is a discrete probability distribution over
initial states, and
\begin{align}
  \bA &=
        \begin{bmatrix}
          \text{---} &  \ba_{1}  & \text{---} \\
            &  \vdots &   \\
          \text{---} &  \ba_{K}  & \text{---}
        \end{bmatrix},
\end{align}
is a~${K \times K}$ transition matrix where the
row,~${\ba_{k} \in [0,1]^K}$, specifies a discrete conditional
distribution over~$z_t$ given~${z_{t-1}=k}$.

This is known as a hidden Markov model (HMM), and in Chapter~\ref{chap:hmms} we 
will study some of the challenges involved in selecting the number of states,~$K$,
in a nonparametric way.

\paragraph{Autoregressive Models}
% Autoregressive observations
In an HMM, correlations in spike counts from one bin to the next arise from 
correlations in the underlying latent states. Alternatively, we may directly 
model the rate as a linear of previous spike counts. For example, consider 
an autoregressive model of the form,
\begin{align}
  \label{eq:ar_model}
  \blambda_{t} &= \sum_{d=1}^D \bW^{(d)} \, \bs_{t-d}.
\end{align}
Compare~\eqref{eq:ar_model} to \eqref{eq:hmm}; rather than having an
autoregresive model for latent states, as in the HMM, here the
autoregression governs the rates directly.  Moreover, this
autoregressive model sums over the past~$D$ time bins, allowing
delayed interactions.  Since the rates must be non-negative, the
weights must be as well.  That is,
~$\bW^{(d)} \in \reals_+^{N \times N}$.

By constraining the weights to be non-negative, we are instantiatign
the hypothesis that the interactions between spikes on one neuron and
the rate of another is always excitatory~---~a spike can never
decrease the future firing rate. While this is not the most
biologically realistic model given our knowledge of excitatory and
inhibitory synapses, it is important to remember that this is simply a
descriptive model of firing rate dynamics, and it does not necessarily
map onto physical synaptic connections. As we will see in
Chapters~\ref{chap:hawkes} and~\ref{chap:discrete_hawkes}, the weights
inferred by this type of excitatory autoregressive model can still
provide useful insight into the structure of neural activity.

\paragraph{Nonlinear Autoregressive Models}
In order to capture both excitatory and inhibitory autoregressive weights,
we need to introduce a nonlinear function that ensure a non-negative firing 
rate. Specifically, assume that,
\begin{align}
  \bpsi_t &= \sum_{d=1}^D \bW^{(d)} \bs_{t-d}, \\
  \blambda_t &= g \left( \bpsi_t \right),
\end{align}
where~${g(\cdot): \reals \to \reals_+}$ is a nonlinear function that
maps a real valued ``activation,''~$\bpsi_t$, into a non-negative
firing rate. Here, we assume~$g$ is applied elementwise. Most
commonly, we use the exponential function~$g(x) = e^x$. In this
formulation the weights,~$\bW^{(d)} \in \reals^{N \times N}$, may be
either positive or negative to reflect either excitatory or inhibitory
interactions, respectively. Chapter~\ref{chap:nonlinear_hawkes}
derives efficient inference algorithms for nonlinear autoregressive
models like these.

\paragraph{Factor Models}
Once we have introduced a nonlinear link between activation and firing
rate, we can revisit the discrete latent states of the mixture model 
and consider their continuous analogues. For example, consider the model,
\begin{align}
  p(\bz) &= \prod_{t=1}^T \distNormal(\bz_t \given \bzero, \bSigma), \\
  \bpsi_t &= \bC \bz_t, \\
  \blambda_t &= g(\bpsi_t),
\end{align}
where~$\bz_t \in \reals^K$,~$\bC \in \reals^{N \times
  K}$, and~${\bSigma = \diag \left([ \sigma^2_1, \ldots, \sigma^2_K ] \right)}$.
This corresponds to a factor analysis model. Unlike standard 
factor analysis, however, here the observations are discrete spike 
counts rather than Gaussian observations. 

\paragraph{Linear Dynamical Systems}
In the same way that HMM's extended mixture models with temporal 
dynamics, linear dynamical systems (LDS's) extend factor models
with linear autoregressive dynamics in the latent state. 
Replace the prior on~$\bz$ with a model of the form,
\begin{align}
  p(\bz) &= \distNormal(\bz_1 \given \bzero, \bSigma) \prod_{t=2}^T \distNormal(\bz_t \given \bA \bz_{t-1}, \bSigma).
\end{align}
The nonlinear mapping from latent states to firing rates is the same
as in the factor model, but now the linear autoregressive nature of
the dynamics induces correlations in spike counts from one time bin to
the next.

% Switching LDS

\paragraph{Hierarchical Extensions}
These motifs --- continuous and discrete latent states, linear autoregressive 
dynamics, and nonlinear link functions --- provide a foundation for 
constructing probabilistic models for spike trains. Atop this foundation 
we may layer additional random variables reflecting hypotheses about shared 
structure. For example, Chapters~\ref{chap:hawkes}, \ref{chap:discrete_hawkes},
and~\ref{chap:nonlinear_hawkes} consider structured prior distributions on 
the weights of autoregressive models, and Chapter~\ref{chap:hmms} considers 
nonparametric Bayesian priors on the number of states in an HMM. Once the 
dynamics model has been specified, it is easy to test a variety of hypotheses
about hierarchical structure. In order to fit these models, however, we need 
efficient inference algorithms that capitalize on the compositional structure 
of the model.


% Inference in this model is not quite as straightforward as in the
% Gaussian case. In Chapter~\ref{chap:discussion}, we discuss some ways
% in which the ideas of Chapter~\ref{chap:nonlinear_hawkes} could be
% extended to

\section{Bayesian Inference}

\subsection{Markov Chain Monte Carlo}

\paragraph{Block Gibbs Sampling}

\paragraph{Augmented Gibbs Sampling}

\paragraph{Collapsed Gibbs Sampling}

\subsection{Variational Inference}

%\subsection{Model Comparison}

\section{The Craft of Modeling}
