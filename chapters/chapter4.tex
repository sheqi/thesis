
\chapter{Dynamic Network Models}

This chapter will extend the previous two chapters to model data with 
underlying networks that change over time according a learning rule. 
This work was originally presented in a 2014 NIPS paper with Chris Stock
and Ryan Adams \cite{linderman2014framework}. Our original paper 
focused specifically on modeling synaptic plasticity, but in this 
thesis I would like to frame it more broadly as a model for networks 
with dynamic weights. I also can introduce inference algorithms that 
are more efficient given the \polyagamma augmentation schemes I have 
since developed, and which were introduced in Chapter 3.

This is the abstract of our 2014 NIPS paper:
Learning and memory in the brain are implemented by complex,
time-varying changes in neural circuitry. The computational rules
according to which synaptic weights change over time are the subject
of much research, and are not precisely understood. Until recently,
limitations in experimental methods have made it challenging to test
hypotheses about synaptic plasticity on a large scale.  However, as
such data become available and these barriers are lifted, it becomes
necessary to develop analysis techniques to validate plasticity
models.  Here, we present a highly extensible framework for modeling
arbitrary synaptic plasticity rules on spike train data in populations
of interconnected neurons. We treat synaptic weights as a (potentially
nonlinear) dynamical system embedded in a fully-Bayesian generalized
linear model (GLM). In addition, we provide an algorithm for inferring
synaptic weight trajectories alongside the parameters of the GLM and
of the learning rules. Using this method, we perform model comparison
of two proposed variants of the well-known spike-timing-dependent
plasticity (STDP) rule, where nonlinear effects play a substantial
role. On synthetic data generated from the biophysical simulator
NEURON, we show that we can recover the weight trajectories, the
pattern of connectivity, and the underlying learning rules.
